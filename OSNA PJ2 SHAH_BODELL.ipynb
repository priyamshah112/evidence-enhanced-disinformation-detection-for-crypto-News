{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e61a55",
   "metadata": {},
   "source": [
    "## <center> OSNA PJ2 </center>\n",
    "### <center> Team 20 - Priyam Shah and WIlliam Bodell </center>\n",
    "### <center> Project Topic: Evidence-enhanced disinformation detection for Crypto News </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12acbc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import re\n",
    "import numpy as np\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "from googlesearch import search\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "import string\n",
    "import math\n",
    "import requests\n",
    "import urllib\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#uncomment below command once to download\n",
    "# nltk.download('punkt') \n",
    "# nltk.download('stopwords')\n",
    "#also install openssl - pip install -U pyopenssl\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 10\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "links=[]\n",
    "evidences=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "914abdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: filter functions - lowercase, remove non-alphanumberic character, word count, related words from a crypto bag\n",
    "\n",
    "def word_count(str):\n",
    "  \"\"\"\n",
    "  word_count function takes in a string and returns integer.\n",
    "  If the word count in input string is greater than six result is 1 else 0\n",
    "  \"\"\"\n",
    "  \n",
    "  word_count = len(str.split())\n",
    "  \n",
    "  if word_count > 6:\n",
    "    return 1\n",
    "  return 0\n",
    "\n",
    "def word_count_evidences(str):\n",
    "  \"\"\"\n",
    "  word_count function takes in a string and returns integer.\n",
    "  If the word count in input string is greater than twenty five result is 1 else 0\n",
    "  \"\"\"\n",
    "  \n",
    "  word_count = len(str.split())\n",
    "  \n",
    "  if word_count > 25:\n",
    "    return 0\n",
    "  return 1\n",
    "\n",
    "def crypto_space_word(str):\n",
    "  \"\"\"\n",
    "  crypto_space_word function takes in a string and returns integer.\n",
    "  If the input string has a single word related to crypto space it returns 1 else 0.\n",
    "  \"\"\"\n",
    "  \n",
    "  crypto_words_list = [\"crypto\",\"cryptos\",\"ethereum\",\"eth\",\"bitcoin\",\"btc\",\"privacy\",\"security\",\"nft\",\"amm\",\"money\",\"cash\",\"coins\",\"swap\",\"chain\",\"digital\",\"currencies\",\"currency\",\"cardano\",\"network\",\"metamask\",\"custodians\",\"tokened\"]\n",
    "  \n",
    "  input_word_list = str.lower().split()\n",
    "  \n",
    "  for i in input_word_list:\n",
    "    if i in crypto_words_list:\n",
    "      return 1\n",
    "  return 0\n",
    "\n",
    "def fake_news_word_count(str):\n",
    "  \"\"\"\n",
    "  fake_news_word function takes in a string and returns integer.\n",
    "  If the input string has a single word related to reporting fake news it returns 1 else 0.\n",
    "  \"\"\"\n",
    "  \n",
    "  fake_news_words_list = [\"fake\", \"hoax\", \"fraud\", \"fraudulent\", \"scam\", \"false\", \"bullshit\", \"vapor\",\"blowout\",\"blowouts\",\"closeouts\",\"closeout\",\"negative\",\"pretending\",\"meaningless\",\"purported\"]\n",
    "  \n",
    "  input_word_list = str.lower().split()\n",
    "  count = 0\n",
    "  for i in input_word_list:\n",
    "    if i in fake_news_words_list:\n",
    "        count += 1\n",
    "        \n",
    "  return count\n",
    "\n",
    "def remove_nonalphanumeric_char(str):\n",
    "  \"\"\" remove_nonalphanumeric_char function takes in a string and returns alpha-numeric character string only.\n",
    "  if the input is \n",
    "  \n",
    "  It would be only fair to conclude the day with a @ShubmanGill\n",
    " & @rahultewatia02 image ðŸ˜‰ ðŸ˜‰\n",
    "\n",
    "  output will be \n",
    "  it would be only fair to conclude the day with a  shubmangill   rahultewatia02 image\n",
    "  \"\"\"\n",
    "  res = re.sub('[^0-9a-zA-Z\\s]+', '',  str)\n",
    "  return res\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11cdf886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: searching article/tweet within known knowledgebase to collect evidences\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\" cleanup all the blank links or evidences which are irrelevant\n",
    "    \"\"\"\n",
    "    global links, evidences\n",
    "\n",
    "    pop_set = set()\n",
    "    for i in range(len(links)):\n",
    "        try:\n",
    "            if links[i] == '':\n",
    "                pop_set.add(i)\n",
    "            if evidences[i] == '' or word_count_evidences(evidences[i]):\n",
    "                pop_set.add(i)\n",
    "        except:\n",
    "            pop_set.add(i)\n",
    "            continue\n",
    "            \n",
    "    rev_pop_set = list(pop_set)\n",
    "    rev_pop_set.sort(reverse=True)\n",
    "\n",
    "    for val in rev_pop_set:\n",
    "\n",
    "        links.pop(val)\n",
    "        evidences.pop(val)\n",
    "\n",
    "            \n",
    "        \n",
    "def summarized_data_from_url(url):\n",
    "  \"\"\" summarized_data_from_url function takes in url and summarizes its parsed content to generate evidence document.\n",
    "  \"\"\"\n",
    "  try:\n",
    "      parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "      stemmer = Stemmer(LANGUAGE)\n",
    "      summarizer = Summarizer(stemmer)\n",
    "      summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "      temp_ans =[]\n",
    "      for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "          #print(sentence)\n",
    "          temp_ans.append(str(sentence))\n",
    "      evidences.append(\"\".join(temp_ans))\n",
    "  \n",
    "  except Exception as e:\n",
    "        print(e)\n",
    "        evidences.append(\"\")\n",
    "        return\n",
    "\n",
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        \n",
    "def search_knowledgebase(query):\n",
    "    \"\"\" search over google for top related links to be termed as evidences for our query.\n",
    "    \"\"\"\n",
    "    global links\n",
    "    \n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    response = get_source(\"https://www.google.co.uk/search?q=\" + query)\n",
    "\n",
    "    links = list(response.html.absolute_links)\n",
    "    google_domains = ('https://www.google.', \n",
    "                      'https://google.', \n",
    "                      'https://webcache.googleusercontent.', \n",
    "                      'http://webcache.googleusercontent.', \n",
    "                      'https://policies.google.',\n",
    "                      'https://support.google.',\n",
    "                      'https://maps.google.')\n",
    "\n",
    "    for url in links[:]:\n",
    "        if url.startswith(google_domains) or url.endswith('.pdf'):\n",
    "            links.remove(url)\n",
    "\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        summarized_data_from_url(link)\n",
    "    \n",
    "    cleanup()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9cb6e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: tf-idf calculation and scoring\n",
    "    \n",
    "#Preprocessing\n",
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)\n",
    "\n",
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"nor\"}\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text\n",
    "\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text\n",
    "\n",
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) \n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data)\n",
    "    return data\n",
    "\n",
    "processed_text = []\n",
    "\n",
    "# Extracting Data\n",
    "def extract_data(evidences,test_article,N):\n",
    "  for i in range(N):\n",
    "    processed_text.append(word_tokenize(str(preprocess(evidences[i]))))\n",
    "  t= document_frequency_calculate(evidences,test_article,N)\n",
    "  return t\n",
    "\n",
    "DF = {}\n",
    "total_vocab_size = len(DF)\n",
    "total_vocab = [x for x in DF]\n",
    "\n",
    "# Calculating Document frequency of words\n",
    "def document_frequency_calculate(evidences,test_article,N):  \n",
    "  for i in range(N):\n",
    "      tokens = processed_text[i]\n",
    "      for w in tokens:\n",
    "          try:\n",
    "              DF[w].add(i)\n",
    "          except:\n",
    "              DF[w] = {i}\n",
    "\n",
    "  for i in DF:\n",
    "      DF[i] = len(DF[i])\n",
    "      \n",
    "  global total_vocab_size\n",
    "  total_vocab_size = len(DF)\n",
    "  global total_vocab\n",
    "  total_vocab = [x for x in DF]\n",
    "  t = tf_idf_calculate(evidences,test_article,N)\n",
    "  return t\n",
    "\n",
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c\n",
    "\n",
    "tf_idf = {}\n",
    "\n",
    "def tf_idf_calculate(evidences,test_article,N):\n",
    "  doc = 0\n",
    "  for i in range(N):\n",
    "      \n",
    "      tokens = processed_text[i]\n",
    "      \n",
    "      counter = Counter(tokens + processed_text[i])\n",
    "      words_count = len(tokens + processed_text[i])\n",
    "      \n",
    "      for token in np.unique(tokens):\n",
    "          \n",
    "          tf = counter[token]/words_count\n",
    "          df = doc_freq(token)\n",
    "          idf = np.log((N+1)/(df+1))\n",
    "          \n",
    "          tf_idf[doc, token] = tf*idf\n",
    "\n",
    "      doc += 1\n",
    "  t = cosine_similarity(N, test_article,evidences,N)\n",
    "  return t\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "\n",
    "def vectorizing_tfidf(evidences,test_article,N):\n",
    "  total_vocab_size = len(DF)\n",
    "  D = np.zeros((N, total_vocab_size))\n",
    "  for i in tf_idf:\n",
    "   try:\n",
    "      ind = total_vocab.index(i[1])\n",
    "      i0=i[0]\n",
    "      D[i0][ind] = tf_idf[i]\n",
    "   except:\n",
    "     pass\n",
    "  return D\n",
    "\n",
    "def gen_vector(tokens,N):\n",
    "    Q = np.zeros((len(total_vocab)))\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "    query_weights = {}\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = math.log((N+1)/(df+1))\n",
    "        try:\n",
    "            ind = total_vocab.index(token)\n",
    "            Q[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return Q\n",
    "\n",
    "\n",
    "\n",
    "#Part 4: final results\n",
    "\n",
    "def cosine_similarity(k,test_article,evidences,N):\n",
    "    D = vectorizing_tfidf(evidences,test_article,N)\n",
    "    tokens = word_tokenize(str(test_article))\n",
    "    d_cosines = []    \n",
    "    query_vector = gen_vector(tokens,N)\n",
    "    \n",
    "    di = 0\n",
    "    for d in D:\n",
    "        sim = cosine_sim(query_vector, d)\n",
    "        fake_word_count = fake_news_word_count(evidences[di])\n",
    "        if fake_word_count > 0:\n",
    "            sim = sim / (fake_word_count*10.0)\n",
    "            \n",
    "        d_cosines.append(sim)\n",
    "        di = di + 1\n",
    "\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Final results~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "    sorted_evidences = [x for _,x in sorted(zip(d_cosines,evidences),reverse=True)]\n",
    "    sorted_urls = [x for _,x in sorted(zip(d_cosines,links),reverse=True)]\n",
    "    d_cosines.sort(reverse=True)\n",
    "    \n",
    "    data_clean = []\n",
    "    for cosine_value in range(len(d_cosines)):\n",
    "        if d_cosines[cosine_value] == 0.0 or math.isnan(d_cosines[cosine_value]):\n",
    "            data_clean.append(cosine_value)\n",
    "    \n",
    "    data_clean.sort(reverse=True)\n",
    "    \n",
    "    for i in range(len(data_clean)):\n",
    "        sorted_evidences.pop(data_clean[i])\n",
    "        sorted_urls.pop(data_clean[i])\n",
    "        d_cosines.pop(data_clean[i])\n",
    "        \n",
    "    for cosine_value in range(len(d_cosines)):\n",
    "        print(\"Evidence \",cosine_value,\": \",sorted_evidences[cosine_value],\"\\nUrl: \",sorted_urls[cosine_value],\"\\nCosine Value: \",d_cosines[cosine_value],\"\\n\\n\")\n",
    "        \n",
    "    final_score = round(sum(d_cosines)/N,3)\n",
    "\n",
    "    return final_score \n",
    "\n",
    "def scoring(evidences,test_article):\n",
    "  N=len(evidences)\n",
    "  score = extract_data(evidences,test_article,N)\n",
    "  return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3d7e0d34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Text :  amazon token is a permissioned blockchain digital currency proposed by the american social media company amazon the project currenct and transactions are to be managed and cryptographically entrusted to the amazon token a membership organization founded by amazon and 27 others across payment technology telecommunication online marketplace venture capital and nonrofits \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Final results~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Evidence  0 :  LACY CLAY, Missouri BILL POSEY, Florida\n",
      "DAVID SCOTT, Georgia BLAINE LUETKEMEYER, Missouri\n",
      "AL GREEN, Texas BILL HUIZENGA, Michigan\n",
      "EMANUEL CLEAVER, Missouri SEAN P. DUFFY, Wisconsin\n",
      "ED PERLMUTTER, Colorado STEVE STIVERS, Ohio\n",
      "JIM A. HIMES, Connecticut ANN WAGNER, Missouri\n",
      "BILL FOSTER, Illinois ANDY BARR, Kentucky\n",
      "JOYCE BEATTY, Ohio SCOTT TIPTON, Colorado\n",
      "DENNY HECK, Washington ROGER WILLIAMS, Texas\n",
      "JUAN VARGAS, California FRENCH HILL, Arkansas\n",
      "JOSH GOTTHEIMER, New Jersey TOM EMMER, Minnesota\n",
      "VICENTE GONZALEZ, Texas LEE M. ZELDIN, New York\n",
      "AL LAWSON, Florida BARRY LOUDERMILK, Georgia\n",
      "MICHAEL SAN NICOLAS, Guam ALEXANDER X. MOONEY, West Virginia\n",
      "RASHIDA TLAIB, Michigan WARREN DAVIDSON, Ohio\n",
      "KATIE PORTER, California TED BUDD, North Carolina\n",
      "CINDY AXNE, Iowa DAVID KUSTOFF, Tennessee\n",
      "SEAN CASTEN, Illinois TREY HOLLINGSWORTH, Indiana\n",
      "AYANNA PRESSLEY, Massachusetts ANTHONY GONZALEZ, Ohio\n",
      "BEN McADAMS, Utah JOHN ROSE, Tennessee\n",
      "ALEXANDRIA OCASIO-CORTEZ, New York BRYAN STEIL, Wisconsin\n",
      "JENNIFER WEXTON, Virginia LANCE GOODEN, Texas\n",
      "STEPHEN F. LYNCH, Massachusetts DENVER RIGGLEMAN, Virginia\n",
      "TULSI GABBARD, Hawaii\n",
      "ALMA ADAMS, North Carolina\n",
      "MADELEINE DEAN, Pennsylvania\n",
      "JESUS ``CHUY'' GARCIA, Illinois\n",
      "SYLVIA GARCIA, Texas\n",
      "DEAN PHILLIPS, Minnesota\n",
      "Charla Ouertatani, Staff Director\n",
      "C O N T E N T S\n",
      "----------\n",
      "Page\n",
      "Hearing held on:\n",
      "July 17, 2019................................................ 1\n",
      "Appendix:\n",
      "July 17, 2019................................................ 113\n",
      "WITNESSES\n",
      "Wednesday, July 17, 2019\n",
      "Brummer, Chris, Professor of Law, Georgetown University Law\n",
      "Center......................................................... 77\n",
      "Demiros, Meltem, Chief Strategy Officer, CoinShares.............. 84\n",
      "Gensler, Hon.Members present: Representatives Waters, Maloney,\n",
      "Velazquez, Sherman, Meeks, Clay, Scott, Green, Perlmutter,\n",
      "Himes, Foster, Beatty, Heck, Vargas, Gottheimer, Lawson, San\n",
      "Nicolas, Tlaib, Porter, Axne, Casten, Pressley, McAdams,\n",
      "Ocasio-Cortez, Wexton, Lynch, Adams, Dean, Garcia of Illinois,\n",
      "Garcia of Texas, Phillips; McHenry, Posey, Luetkemeyer,\n",
      "Huizenga, Duffy, Stivers, Wagner, Barr, Tipton, Williams, Hill,\n",
      "Emmer, Zeldin, Loudermilk, Davidson, Budd, Kustoff,\n",
      "Hollingsworth, Gonzalez of Ohio, Rose, Steil, Gooden, and\n",
      "Riggleman.In light of these and other concerns, my colleagues and I\n",
      "wrote to Facebook earlier this month to call on it to cease\n",
      "implementation of its plans until regulators and Congress can\n",
      "examine the issues associated with a large technology company\n",
      "developing a digital currency, and take action.Will you stop kind of dancing around this question and commit\n",
      "here, in this committee, before the duly elected\n",
      "Representatives of the American people, to a moratorium until\n",
      "Congress enacts an appropriate legal framework to ensure that\n",
      "Libra and Calibra do what you claim it is intended to do, which\n",
      "to serve the public good?There are a lot of illicit activities that are currently\n",
      "happening in our existing financial system, and I actually\n",
      "believe that with the combination of the right technology and\n",
      "the ability for law enforcement and regulators to also have a\n",
      "view into some of the movements, that we will improve on the\n",
      "efficacy of AML and counterterrorism funding programs.In connection with that fine,\n",
      "consider this: The FTC's investigation was set off by a New\n",
      "York Times and Observer of London report which uncovered that\n",
      "Facebook, the social network, allowed Cambridge Analytica, a\n",
      "British consulting firm to the Trump campaign, to harvest\n",
      "personal information of its users.The White Paper is no mere public brainstorming exercise or\n",
      "a technical exposition, but is instead intended to condition\n",
      "the market for the adoption of a product that Facebook wishes\n",
      "to sell to billions of people around the world, and the lapses\n",
      "are all the more problematic given the securities-like features\n",
      "of Libra coins and possible implication of U.S. securities\n",
      "laws.In that White Paper, it states that globally, 1.7 billion\n",
      "adults remain outside of the financial system with no access to\n",
      "traditional banks, and I questioned him on that and he assured\n",
      "me that in order to obtain what he called a Calibra Wallet,\n",
      "there must be strong Know- Your-Customer requirements in place,\n",
      "including a government-issued ID, and this is particularly\n",
      "acute when you're dealing with online activity.And I'll put the questions into the\n",
      "record, Madam Chairwoman, if that's permitted, but I want you\n",
      "all to know, one of the things I told Mr. Marcus is about the\n",
      "monopoly, the small group of friends that is being created\n",
      "with--the fact that a member can vote in contrary to the\n",
      "position advocated for Facebook, what would happen, what\n",
      "retaliation?As a matter of fact, you heard some of our Members today\n",
      "talk about--I think it was Mr. Meeks, he never envisioned what\n",
      "was to happen in 2008 with that subprime meltdown that we had\n",
      "with our financial institutions basically hitting the dust and\n",
      "leaving everybody hanging and all of the harm that was done to\n",
      "our constituents and communities where foreclosures took place\n",
      "and people had been involved and signing on the dotted line for\n",
      "mortgages that they didn't understand. \n",
      "Url:  https://www.govinfo.gov/content/pkg/CHRG-116hhrg39740/html/CHRG-116hhrg39740.htm \n",
      "Cosine Value:  0.033677288171145715 \n",
      "\n",
      "\n",
      "Evidence  1 :  There has been a lot of rumor and speculation circulating in the crypto and mainstream media recently regarding e-commerce giant Amazon moving into the crypto-space by accepting select cryptocurrencies as payment options.The blockchain descriptor page for Amazon shows that AWS currently supports \"25 percent of all Ethereum workloads in the world.\"They're designed to touch and improve many aspects of life, including data security, insurance, physical property, social media, music, movies, health information, identity, marketplaces, finance, gaming, bill payment, as well as many others.For instance, you likely know and have heard about non-fungible tokens (NFTs), but what you may not know is that nearly the entire NFT environment from concept-to-commerce runs on the Ethereum blockchain network.This week Ethereum made several major programming upgrades to its network-- known as the \"London hard fork\"-- which will significantly lower transactions fees and make it a deflationary asset .DeFi is a system where blockchain-based software-- smart contracts for short--allows direct peer-to-peer buying, selling, lending, and borrowing without bankers or brokers in the middle taking a piece.All said, I believe Amazon will likely ease into accepting certain crypto payments for its retail web store before the end of 2021.The move could save Amazon hundreds of millions annually in credit card processing fees and significantly reduce exposure to credit card chargebacks, and blockchain payments would reduce fraudulent transactions.A \"trusted\" Amazon DeFi suite of services might be a welcome alternative to many customers who are tired of bank fees, invasive credit checks, fractional interest rates, and long settlement timelines.Lastly, the AWS page has a paragraph that should make JPMorgan CEO Jaime Dimon and every other banking executive quake in their Ferragamo loafers because it reads:AWS provides purpose-built tools to support your distinct needs, whether you need a centralized ledger database that maintains an immutable and cryptographically verifiable record of transactions, or a multi-party, fully managed blockchain network that helps eliminate intermediaries. \n",
      "Url:  https://www.inc.com/tor-constantino/why-amazon-will-likely-make-a-massive-move-into-crypto.html \n",
      "Cosine Value:  0.020098636381591713 \n",
      "\n",
      "\n",
      "Evidence  2 :  Table of contents Financial services Travel & mobility Infrastructure & energy Healthcare Government Retail & CPG Agriculture & natural resources Information & communication Entertainment Enterprise techThe crowdfunding industry emerged to â€œdisintermediateâ€ capital formation by giving backers (aka â€œpledgersâ€) or individual investors the ability to directly fund creators and entrepreneurs, providing a natural alignment with blockchain capabilities.In 2017, South Koreaâ€™s logistics company Hyundai Merchant Marine (HMM) held trial runs using a blockchain system developed with Samsung SDS that utilized IoT devices for real-time monitoring.Using blockchain to support these evolving infrastructures can eliminate security vulnerabilities, protect intellectual property from theft, and streamline project management, ultimately helping the 3D printing and additive manufacturing sectors to grow and scale.Blockchain technology could also help ensure construction materials are sourced from the right places and are of the appropriate quality, while smart contracts may make it simpler to automatically issue timely payments linked to project milestones.In the future, blockchain tools could serve as a foundational infrastructure for casting, tracking, and counting votes â€” potentially eliminating the need for recounts by taking voter fraud and foul play off the table.Consumers will be able to scan a QR code with their smartphone to trace the fish â€œfrom bait to plateâ€ and confirm that theyâ€™re buying legally caught, sustainable tuna with no slave labor or oppressive working conditions involved.Entertainment entrepreneurs are turning to blockchain technology to make content sharing fairer for creators using smart contracts, whereby the revenue on purchases of creative work can be automatically disseminated according to pre-determined licensing agreements.The technology helps ensure fair games â€” records canâ€™t be manipulated on the ledger, so thereâ€™s no such thing as â€œthe house always wins.â€ Sites like Wagerr play on the idea of â€œtrustless betting,â€ meaning that the system is so decentralized, you donâ€™t need trust.For example, the artist Beeple uses NFTs, which are based on blockchain tech, to create a unique signature for each piece of art he sells, enabling him to track each work, earn royalty payments, and avoid forgeries. \n",
      "Url:  https://www.cbinsights.com/research/industries-disrupted-blockchain/ \n",
      "Cosine Value:  0.012233155231810617 \n",
      "\n",
      "\n",
      "Evidence  3 :  The rumors originated from news stories reporting that Amazon could be entering the cryptocurrency market and creating their own tokens as part of that.These malicious advertisements rely on peopleâ€™s trust in the Amazon brand and desire to get in early on cryptocurrency initial coin offerings (ICOs).Once someone clicks on one of these malicious ads, they are redirected to a well-constructed website that appears to be promoting Amazonâ€™s new (nonexistent) Token cryptocurrency.The website even cleverly connects the purchase of the nonexistent token with free Amazon Prime membership, making it seem even more legitimate.The attackers behind this scam also cleverly tie the purchase of these nonexistent tokens to Amazonâ€™s Prime Gaming service , meant to appeal to gamers.There is a countdown on the website and sales and bonuses if the user decides to purchase immediately, a classic scammer tactic of using time pressure to force prospective victims into making quick (and bad) decisions.Once the user creates an account, there is a legitimate-looking dashboard that allows the management of the fake cryptocurrency portfolio, including the opportunity to make purchases of the nonexistent Amazon Tokens.We have seen the malicious ads spread around the world, in the U.S., Canada, Brazil, Venezuela, UK, Ireland, Norway, France, Germany, Austria, Switzerland, Netherlands, Italy, Spain, Poland, Czech Republic, Slovakia, Hungary, Estonia, Latvia, Ukraine, Serbia, Bosnia And Herzegovina, Montenegro, Macedonia, Greece, Romania, Bulgaria, Georgia, Morocco, Nigeria, Indonesia, Philippines, and Australia.Scammers latch onto fresh news like this, as the general perception of cryptocurrency is that early adopters can make significant gains if the currency proves successful.The fact that these scams are so well-constructed and abuse the Amazon name, branding, and trust -- and are occurring during the holiday shopping season -- makes them all the more insidious. \n",
      "Url:  https://blog.avast.com/beware-of-a-new-amazon-token-crypto-scam \n",
      "Cosine Value:  0.00944650987227581 \n",
      "\n",
      "\n",
      "Evidence  4 :  In July, reports surfaced that Amazon was planning to announce a digital currency.After all, it clearly has the backing of Jeff Bezos, with the Amazon logo and his picture right there.Why was there no official press release or news coverage from Amazon?Notice the subtle clues that the opportunity is limited so youâ€™d better act now.I canâ€™t imagine a legitimate Amazon site saying something quite as meaningless as â€œeverything is secure and robust.â€ This isnâ€™t the usual marketing bullshit, itâ€™s just garden-variety super-vague writing.A Whois search reveals that both of those domains are registered with privacy on, so you can get no information about who actually owns them.If you invest in this site, youâ€™ll pay real money for Bitcoin or another cryptocurrency and trade it for an â€œAmazon Tokenâ€ where the only connection with Amazon is photos of Jeff Bezos pasted into the site.Facebook should have caught this, since the ad was clearly placed by somebody pretending to have an Amazon connection.Try to find links from the referenced company (in this case, Amazon) out to the purported site.And shockingly, in the time it took me write this blog post, the advertiserâ€™s Facebook account has been suspended. \n",
      "Url:  https://withoutbullshit.com/blog/why-the-amazon-token-advertised-on-facebook-sure-looks-like-a-scam \n",
      "Cosine Value:  0.0071454458179975545 \n",
      "\n",
      "\n",
      "Evidence  5 :  [16] On September 18, 2019, during a meeting with top Senate Democratic leaders, Mark Zuckerberg said that Libra would not be launched anywhere in the world without first obtaining approval from United States regulators.According to a November 2020 report in the Financial Times , Libra will be launching a slimmed down plan that includes the cryptocurrency being a stablecoin backed by the US dollar rather than a multiple currency collection.On April 16, 2020, Libra announced plans to create an infrastructure for multiple cryptocurrencies, the preponderance of which will be backed by individual fiat currencies , and said the association was in talks with regulators from Switzerland for a payments license .In May 2021, Diem announced that it had withdrawn its application to the Swiss Financial Market Supervisory Authority and said that it would instead seek approval with the US treasury to register as a money services business.Bank of England governor Mark Carney said there was a need to keep an \"open mind\" about new technology for money transfers, but \"anything that works in this world will become instantly systemic and will have to be subject to the highest standards of regulation.\"[60] The U.S. House Committee on Financial Services Democrats sent a letter to Facebook asking the company to stop development of Libra, citing concerns of privacy, national security , trading, and monetary policy .Jerome Powell , chairman of the Federal Reserve , testified before Congress on 10 July 2019 that the Fed had \"serious concerns\" as to how Libra would deal with \"money laundering, consumer protection and financial stability.\"In general, consumer advocates and public interest groups have opposed Diem on privacy grounds and rejected the tethering of financial services to mass surveillance.At the time, the software did little more than allow fake coins to be put in a wallet ; almost none of the functionality outlined in the white paper was implemented, including \"major architectural features that have yet to be invented.\"In order to abide by standard \"know-your-customer\" and \"anti-money laundering\" laws, Calibra will have to verify people's identities through a thorough process, collecting government-issued IDs and other personal details and documentation. \n",
      "Url:  https://en.wikipedia.org/wiki/Diem_(digital_currency) \n",
      "Cosine Value:  0.003604626893080151 \n",
      "\n",
      "\n",
      "Average cosine similarity value for query and evidences is  0.014 \n",
      "\n",
      "Negative ðŸ˜ž!, Content seems to be opposed by evidences\n"
     ]
    }
   ],
   "source": [
    "#Script for single news/article testing\n",
    "#Driver function and single article test - replace string in test_article with your news/article for testing\n",
    "if __name__ == \"__main__\":    \n",
    "    test_article = \"Amazon Token is a permissioned blockchain digital currency proposed by the American social media company Amazon. The project, currenct and transactions are to be managed and cryptographically entrusted to the Amazon Token, a membership organization founded by Amazon and 27 others across payment, technology, telecommunication, online marketplace, venture capital and nonrofits.\"\n",
    "\n",
    "    #Part 1: filter functions - lowercase, remove non-alphanumberic character, word count, related words from a crypto bag\n",
    "    test_article=test_article.lower()\n",
    "    test_article=remove_nonalphanumeric_char(test_article)\n",
    "    if not crypto_space_word(test_article):\n",
    "      print(\"Text content not from crypto space.\")\n",
    "      sys.exit(0)\n",
    "\n",
    "    if not word_count(test_article):\n",
    "      print(\"Too few words to verify!\")\n",
    "      sys.exit(0)\n",
    "\n",
    "    print(\"Query Text : \",test_article,\"\\n\")\n",
    "    \n",
    "    #Part 2: searching article/tweet within known knowledgebase to collect evidences\n",
    "    search_knowledgebase(test_article)\n",
    "    \n",
    "    #Part 3: tf-idf calculation and scoring\n",
    "    #Part 4: final results\n",
    "    score=scoring(evidences,test_article)\n",
    "    \n",
    "    print(\"Average cosine similarity value for query and evidences is \", score,\"\\n\")\n",
    "    \n",
    "    if score > 0.05:\n",
    "        print(\"Positive ðŸ˜†!, Content seems to be supported by evidences\")\n",
    "    elif score<0.05 and score>0.00:\n",
    "        print(\"Negative ðŸ˜ž!, Content seems to be opposed by evidences\")\n",
    "    else:\n",
    "        print(\"Very low score to predict a judgement ðŸ™ˆ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01faa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
